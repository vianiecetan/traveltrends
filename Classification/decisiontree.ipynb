{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixpdbi1wqnVG",
        "outputId": "849fc711-e588-455d-94f7-72bf4b090961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of rows in training dataset: 4965\n",
            "\n",
            "First few rows of the training dataset:\n",
            "   Month  Year         Country  Departures  Arrivals  Total Holidays  \\\n",
            "0      1  2000  United Kingdom     46677.0   45630.0        1.015023   \n",
            "1      1  2000         Germany     23172.0   24251.0        1.015023   \n",
            "2      1  2000          France     11098.0   11469.0        1.015023   \n",
            "3      1  2000          Europe    118255.0  119735.0        1.015023   \n",
            "4      1  2000         Oceania    139244.0  133358.0        1.015023   \n",
            "\n",
            "   Inflation  Month_sin  Month_cos  Total_Traffic  Traffic_Class  \n",
            "0  -0.600846        0.5   0.866025        92307.0              0  \n",
            "1  -0.407217        0.5   0.866025        47423.0              0  \n",
            "2  -0.278131        0.5   0.866025        22567.0              0  \n",
            "3  -0.278131        0.5   0.866025       237990.0              1  \n",
            "4  -0.278131        0.5   0.866025       272602.0              1   \n",
            "\n",
            "Training dataset description:\n",
            "             Month         Year    Departures      Arrivals  Total Holidays  \\\n",
            "count  4965.000000  4965.000000  4.965000e+03  4.965000e+03     4965.000000   \n",
            "mean      6.501913  2010.998590  1.482594e+05  1.496660e+05       -0.000613   \n",
            "std       3.452312     6.631624  1.878581e+05  1.906406e+05        0.999368   \n",
            "min       1.000000  2000.000000  7.700000e+01  3.700000e+01       -1.014614   \n",
            "25%       4.000000  2005.000000  3.215800e+04  3.226200e+04       -1.014614   \n",
            "50%       7.000000  2011.000000  9.459000e+04  9.670000e+04        0.000204   \n",
            "75%      10.000000  2017.000000  1.797090e+05  1.818210e+05        1.015023   \n",
            "max      12.000000  2022.000000  1.352214e+06  1.354850e+06        4.059479   \n",
            "\n",
            "         Inflation     Month_sin     Month_cos  Total_Traffic  Traffic_Class  \n",
            "count  4965.000000  4.965000e+03  4.965000e+03   4.965000e+03    4965.000000  \n",
            "mean      0.000281 -3.758359e-04  1.007049e-04   2.979254e+05       1.000000  \n",
            "std       1.000204  7.072135e-01  7.071424e-01   3.781929e+05       0.816579  \n",
            "min      -1.439905 -1.000000e+00 -1.000000e+00   3.050000e+02       0.000000  \n",
            "25%      -0.633118 -8.660254e-01 -5.000000e-01   6.388800e+04       0.000000  \n",
            "50%      -0.245860 -2.449294e-16  6.123234e-17   1.908630e+05       1.000000  \n",
            "75%       0.270484  5.000000e-01  5.000000e-01   3.617230e+05       2.000000  \n",
            "max       6.595696  1.000000e+00  1.000000e+00   2.707064e+06       2.000000   \n",
            "\n",
            "Training dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4965 entries, 0 to 4964\n",
            "Data columns (total 11 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   Month           4965 non-null   int64  \n",
            " 1   Year            4965 non-null   int64  \n",
            " 2   Country         4965 non-null   object \n",
            " 3   Departures      4965 non-null   float64\n",
            " 4   Arrivals        4965 non-null   float64\n",
            " 5   Total Holidays  4965 non-null   float64\n",
            " 6   Inflation       4965 non-null   float64\n",
            " 7   Month_sin       4965 non-null   float64\n",
            " 8   Month_cos       4965 non-null   float64\n",
            " 9   Total_Traffic   4965 non-null   float64\n",
            " 10  Traffic_Class   4965 non-null   int64  \n",
            "dtypes: float64(7), int64(3), object(1)\n",
            "memory usage: 426.8+ KB\n",
            "\n",
            "Selected features (importance > 0.1): ['Total_Traffic']\n",
            "\n",
            "Untuned Model Evaluation:\n",
            "Training Accuracy: 1.0000\n",
            "Validation Accuracy: 0.9993\n",
            "10-Fold CV Accuracy: Mean = 0.9991, Std = 0.0013\n",
            "\n",
            "Confusion Matrix:\n",
            "[[474   0   0]\n",
            " [  0 502   1]\n",
            " [  0   0 513]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       474\n",
            "           1       1.00      1.00      1.00       503\n",
            "           2       1.00      1.00      1.00       513\n",
            "\n",
            "    accuracy                           1.00      1490\n",
            "   macro avg       1.00      1.00      1.00      1490\n",
            "weighted avg       1.00      1.00      1.00      1490\n",
            "\n",
            "\n",
            "GridSearchCV Results:\n",
            "Best Parameters: {'criterion': 'gini', 'max_depth': 6, 'min_weight_fraction_leaf': 0.0, 'splitter': 'best'}\n",
            "Best Cross-Validation Score: 0.9991\n",
            "\n",
            "Tuned Model Evaluation:\n",
            "Training Accuracy: 1.0000\n",
            "Validation Accuracy: 0.9993\n",
            "10-Fold CV Accuracy: Mean = 0.9991, Std = 0.0013\n",
            "\n",
            "Confusion Matrix:\n",
            "[[474   0   0]\n",
            " [  0 502   1]\n",
            " [  0   0 513]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       474\n",
            "           1       1.00      1.00      1.00       503\n",
            "           2       1.00      1.00      1.00       513\n",
            "\n",
            "    accuracy                           1.00      1490\n",
            "   macro avg       1.00      1.00      1.00      1490\n",
            "weighted avg       1.00      1.00      1.00      1490\n",
            "\n",
            "\n",
            "Final Test Dataset Evaluation (2023-2025):\n",
            "Testing Accuracy: 0.1314\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 59   0   0]\n",
            " [163   0   0]\n",
            " [227   0   0]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.13      1.00      0.23        59\n",
            "           1       0.00      0.00      0.00       163\n",
            "           2       0.00      0.00      0.00       227\n",
            "\n",
            "    accuracy                           0.13       449\n",
            "   macro avg       0.04      0.33      0.08       449\n",
            "weighted avg       0.02      0.13      0.03       449\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# 1. Import Libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# 2. Load and Display Training Dataset (Initial Exploratory Data Analysis)\n",
        "df_train = pd.read_csv(\"train_data_with_traffic_class.csv\")\n",
        "print(f\"Total number of rows in training dataset: {len(df_train)}\\n\")\n",
        "print(\"First few rows of the training dataset:\")\n",
        "print(df_train.head(), \"\\n\")\n",
        "print(\"Training dataset description:\")\n",
        "print(df_train.describe(), \"\\n\")\n",
        "print(\"Training dataset info:\")\n",
        "df_train.info()\n",
        "\n",
        "# 3. Define Features and Target Variable for Training with Consistent Preprocessing\n",
        "X_train_full = df_train.drop(columns=['Traffic_Class'])\n",
        "y_train_full = df_train['Traffic_Class']\n",
        "\n",
        "# One-hot encode categorical variables for training data\n",
        "X_train_full = pd.get_dummies(X_train_full, columns=[\"Country\"], drop_first=True)\n",
        "\n",
        "# 4. Split Training Data into Training and Validation Sets (70%/30%)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.3, random_state=42)\n",
        "\n",
        "# 5. Feature Selection on the Training Set\n",
        "# Fit a base Decision Tree to determine feature importances\n",
        "base_model = DecisionTreeClassifier(random_state=42)\n",
        "base_model.fit(X_train, y_train)\n",
        "importances = base_model.feature_importances_\n",
        "\n",
        "# Select features with importance greater than a threshold (e.g., 0.1)\n",
        "threshold = 0.1\n",
        "selected_features = X_train.columns[importances > threshold]\n",
        "print(f\"\\nSelected features (importance > {threshold}): {selected_features.tolist()}\")\n",
        "\n",
        "# Filter training and validation sets to keep only the selected features\n",
        "X_train_selected = X_train[selected_features]\n",
        "X_val_selected = X_val[selected_features]\n",
        "\n",
        "# 6. Train and Evaluate the Untuned Model on Training and Validation Sets\n",
        "untuned_model = DecisionTreeClassifier(random_state=42)\n",
        "untuned_model.fit(X_train_selected, y_train)\n",
        "\n",
        "train_accuracy_untuned = untuned_model.score(X_train_selected, y_train)\n",
        "val_accuracy_untuned = accuracy_score(y_val, untuned_model.predict(X_val_selected))\n",
        "cv_scores_untuned = cross_val_score(estimator=untuned_model, X=X_train_selected, y=y_train, cv=10)\n",
        "cm_untuned = confusion_matrix(y_val, untuned_model.predict(X_val_selected))\n",
        "classification_report_untuned = classification_report(y_val, untuned_model.predict(X_val_selected))\n",
        "\n",
        "print(\"\\nUntuned Model Evaluation:\")\n",
        "print(f\"Training Accuracy: {train_accuracy_untuned:.4f}\")\n",
        "print(f\"Validation Accuracy: {val_accuracy_untuned:.4f}\")\n",
        "print(f\"10-Fold CV Accuracy: Mean = {cv_scores_untuned.mean():.4f}, Std = {cv_scores_untuned.std():.4f}\")\n",
        "print(f\"\\nConfusion Matrix:\\n{cm_untuned}\")\n",
        "print(f\"\\nClassification Report:\\n{classification_report_untuned}\")\n",
        "\n",
        "# 7. Hyperparameter Tuning (Using GridSearchCV on the Training Set)\n",
        "param_grid = {\n",
        "    'max_depth': [6, 8, 10],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'splitter': ['best', 'random'],\n",
        "    'min_weight_fraction_leaf': [0.0, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=untuned_model, param_grid=param_grid, cv=5)\n",
        "grid_search.fit(X_train_selected, y_train)\n",
        "\n",
        "print(\"\\nGridSearchCV Results:\")\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best Cross-Validation Score: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# 8. Train and Evaluate the Tuned Model on the Validation Set\n",
        "tuned_model = grid_search.best_estimator_\n",
        "tuned_model.fit(X_train_selected, y_train)\n",
        "\n",
        "train_accuracy_tuned = tuned_model.score(X_train_selected, y_train)\n",
        "val_accuracy_tuned = accuracy_score(y_val, tuned_model.predict(X_val_selected))\n",
        "cv_scores_tuned = cross_val_score(estimator=tuned_model, X=X_train_selected, y=y_train, cv=10)\n",
        "cm_tuned = confusion_matrix(y_val, tuned_model.predict(X_val_selected))\n",
        "classification_report_tuned = classification_report(y_val, tuned_model.predict(X_val_selected))\n",
        "\n",
        "print(\"\\nTuned Model Evaluation:\")\n",
        "print(f\"Training Accuracy: {train_accuracy_tuned:.4f}\")\n",
        "print(f\"Validation Accuracy: {val_accuracy_tuned:.4f}\")\n",
        "print(f\"10-Fold CV Accuracy: Mean = {cv_scores_tuned.mean():.4f}, Std = {cv_scores_tuned.std():.4f}\")\n",
        "print(f\"\\nConfusion Matrix:\\n{cm_tuned}\")\n",
        "print(f\"\\nClassification Report:\\n{classification_report_tuned}\")\n",
        "\n",
        "# 9. Load and Preprocess the New Testing Dataset (2023-2025)\n",
        "df_test = pd.read_csv(\"test_data_with_traffic_class.csv\")\n",
        "\n",
        "# Define test features and target variable as specified\n",
        "# Drop columns that are not needed for prediction\n",
        "X_test_raw = df_test.drop(columns=[\"Total_Traffic\", \"Departures\", \"Arrivals\", \"Traffic_Class\", \"Month_sin\", \"Month_cos\"])\n",
        "y_test = df_test[\"Traffic_Class\"]\n",
        "\n",
        "# One-hot encode the test dataset for categorical variables\n",
        "X_test_encoded = pd.get_dummies(X_test_raw, columns=[\"Country\"], drop_first=True)\n",
        "\n",
        "# Align test features with the training set features\n",
        "# (Missing columns will be filled with 0; extra columns are dropped)\n",
        "X_test_aligned = X_test_encoded.reindex(columns=X_train_full.columns, fill_value=0)\n",
        "\n",
        "# Apply the same feature selection from training\n",
        "X_test_selected = X_test_aligned[selected_features]\n",
        "\n",
        "# Evaluate the tuned model on the test dataset\n",
        "test_accuracy_final = accuracy_score(y_test, tuned_model.predict(X_test_selected))\n",
        "cm_final = confusion_matrix(y_test, tuned_model.predict(X_test_selected))\n",
        "classification_report_final = classification_report(y_test, tuned_model.predict(X_test_selected))\n",
        "\n",
        "print(\"\\nFinal Test Dataset Evaluation (2023-2025):\")\n",
        "print(f\"Testing Accuracy: {test_accuracy_final:.4f}\")\n",
        "print(f\"\\nConfusion Matrix:\\n{cm_final}\")\n",
        "print(f\"\\nClassification Report:\\n{classification_report_final}\")"
      ]
    }
  ]
}