{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering\n",
    "df = pd.read_csv(\"../preprocessing/train_data.csv\")\n",
    "#time-based features\n",
    "# Define mapping of month names to numbers\n",
    "month_mapping = {\n",
    "    'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n",
    "    'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12\n",
    "}\n",
    "\n",
    "df['Month'] = df['Month'].map(month_mapping)\n",
    "\n",
    "# Sort by Year and Month (ascending order)\n",
    "df = df.sort_values(by=['Year', 'Month'], ascending=[True, True]).reset_index(drop=True)\n",
    "\n",
    "# convert month to integer type\n",
    "df['Month'] = df['Month'].astype(int)\n",
    "\n",
    "# Create a 'Quarter' feature\n",
    "df['Quarter'] = ((df['Month'] - 1) // 3) + 1\n",
    "\n",
    "df['Years_Since_2000'] = df['Year'] - 2000\n",
    "\n",
    "df['Departures_Growth'] = df.groupby('Country')['Departures'].pct_change()\n",
    "df['Arrivals_Growth'] = df.groupby('Country')['Arrivals'].pct_change()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmapped Countries: []\n"
     ]
    }
   ],
   "source": [
    "#geographical data\n",
    "# Define a dictionary to map countries to broader geographical regions\n",
    "region_mapping = {\n",
    "    'France': 'Europe',\n",
    "    'Germany': 'Europe',\n",
    "    'United Kingdom': 'Europe',\n",
    "    \n",
    "    'Indonesia': 'South East Asia',\n",
    "    'Malaysia': 'South East Asia',\n",
    "    'Philippines': 'South East Asia',\n",
    "    'Thailand': 'South East Asia',\n",
    "    'Vietnam': 'South East Asia',\n",
    "\n",
    "    'Mainland China': 'East Asia',\n",
    "    'Japan': 'East Asia',\n",
    "    'Hong Kong': 'East Asia',\n",
    "    \n",
    "    'South Asia': 'South Asia',  # Already a region\n",
    "    'South East Asia': 'South East Asia',  # Already a region\n",
    "    'North East Asia': 'East Asia',  # Adjusted for consistency\n",
    "\n",
    "    'Middle East': 'Middle East',  # Already a region\n",
    "    'North America': 'North America',  # Already a region\n",
    "    'Oceania': 'Oceania',  # Already a region\n",
    "    'Europe': 'Europe',  # Already a region\n",
    "}\n",
    "\n",
    "# Standardize country names (remove extra spaces)\n",
    "df['Country'] = df['Country'].str.strip()\n",
    "\n",
    "# Create a new column 'Region' based on the mapping\n",
    "df['Region'] = df['Country'].map(region_mapping)\n",
    "\n",
    "# Check if any country was not mapped (helps in debugging)\n",
    "unmapped_countries = df[df['Region'].isna()]['Country'].unique()\n",
    "print(\"Unmapped Countries:\", unmapped_countries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encode region\n",
    "df = pd.get_dummies(df, columns=['Region'], prefix='Region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vianiece\\AppData\\Local\\Temp\\ipykernel_4580\\3205859310.py:2: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
      "  df['Departures_Growth'] = df.groupby('Country')['Departures_Growth'].fillna(0)\n",
      "C:\\Users\\Vianiece\\AppData\\Local\\Temp\\ipykernel_4580\\3205859310.py:3: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
      "  df['Arrivals_Growth'] = df.groupby('Country')['Arrivals_Growth'].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "# Fill NaN values in the first few rows (likely due to pct_change()) with 0\n",
    "df['Departures_Growth'] = df.groupby('Country')['Departures_Growth'].fillna(0)\n",
    "df['Arrivals_Growth'] = df.groupby('Country')['Arrivals_Growth'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated train_data.csv saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the updated dataset back to the train CSV\n",
    "df.to_csv(\"../preprocessing/train_data.csv\", index=False)\n",
    "\n",
    "print(\"Updated train_data.csv saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Month  Year         Country  Departures  Arrivals  Quarter  \\\n",
      "0      1  2000   North America     29012.0   26225.0        1   \n",
      "1      1  2000   North America     29012.0   26225.0        1   \n",
      "2      1  2000  United Kingdom     46677.0   45630.0        1   \n",
      "3      1  2000  United Kingdom     46677.0   45630.0        1   \n",
      "4      1  2000         Germany     23172.0   24251.0        1   \n",
      "\n",
      "   Years_Since_2000  Departures_Growth  Arrivals_Growth  Region_East Asia  \\\n",
      "0                 0                0.0              0.0             False   \n",
      "1                 0                0.0              0.0             False   \n",
      "2                 0                0.0              0.0             False   \n",
      "3                 0                0.0              0.0             False   \n",
      "4                 0                0.0              0.0             False   \n",
      "\n",
      "   Region_Europe  Region_Middle East  Region_North America  Region_Oceania  \\\n",
      "0          False               False                  True           False   \n",
      "1          False               False                  True           False   \n",
      "2           True               False                 False           False   \n",
      "3           True               False                 False           False   \n",
      "4           True               False                 False           False   \n",
      "\n",
      "   Region_South Asia  Region_South East Asia            Event  \n",
      "0              False                   False   New Year’s Day  \n",
      "1              False                   False  Hari Raya Puasa  \n",
      "2              False                   False   New Year’s Day  \n",
      "3              False                   False  Hari Raya Puasa  \n",
      "4              False                   False   New Year’s Day  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the holiday data\n",
    "holidays_df = pd.read_csv(\"../Dataset/singapore_holidays.csv\")\n",
    "\n",
    "# Convert 'Date' to datetime, handling the format 'YYYY-MM-DD'\n",
    "holidays_df['Date'] = pd.to_datetime(holidays_df['Date'], format='%Y-%m-%d')\n",
    "\n",
    "# Extract 'Month' and 'Year' from 'Date' for matching with the main dataset\n",
    "holidays_df['Month'] = holidays_df['Date'].dt.month\n",
    "holidays_df['Year'] = holidays_df['Date'].dt.year\n",
    "\n",
    "# Load the main dataset\n",
    "df = pd.read_csv(\"../preprocessing/train_data.csv\")\n",
    "\n",
    "# Merge the main dataset with holiday dataset on both Year and Month\n",
    "df = pd.merge(df, holidays_df[['Year', 'Month', 'Event']], \n",
    "              how='left', on=['Year', 'Month'])\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Create a flag for holiday presence in the month\n",
    "df['Is_Holiday_Month'] = df['Event'].notna().astype(int)\n",
    "\n",
    "# Optionally, drop the 'Event' column if you just want the flag\n",
    "df = df.drop(columns=['Event'])\n",
    "\n",
    "# Save the updated dataset with holidays\n",
    "df.to_csv(\"train_data_with_holidays.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 1296\n",
      "      Month  Year         Country  Departures  Arrivals  Quarter  \\\n",
      "1         1  2000   North America     29012.0   26225.0        1   \n",
      "3         1  2000  United Kingdom     46677.0   45630.0        1   \n",
      "5         1  2000         Germany     23172.0   24251.0        1   \n",
      "7         1  2000          France     11098.0   11469.0        1   \n",
      "9         1  2000          Europe    118255.0  119735.0        1   \n",
      "...     ...   ...             ...         ...       ...      ...   \n",
      "4889      8  2019     Middle East     91493.0   79405.0        3   \n",
      "4891      8  2019      South Asia    244304.0  262089.0        3   \n",
      "4892      8  2019      South Asia    244304.0  262089.0        3   \n",
      "4894      8  2019           Japan    151982.0  149519.0        3   \n",
      "4895      8  2019           Japan    151982.0  149519.0        3   \n",
      "\n",
      "      Years_Since_2000  Departures_Growth  Arrivals_Growth  Region_East Asia  \\\n",
      "1                    0           0.000000          0.00000             False   \n",
      "3                    0           0.000000          0.00000             False   \n",
      "5                    0           0.000000          0.00000             False   \n",
      "7                    0           0.000000          0.00000             False   \n",
      "9                    0           0.000000          0.00000             False   \n",
      "...                ...                ...              ...               ...   \n",
      "4889                19           0.246821         -0.10038             False   \n",
      "4891                19           0.029750          0.03536             False   \n",
      "4892                19           0.029750          0.03536             False   \n",
      "4894                19           0.256382          0.12254              True   \n",
      "4895                19           0.256382          0.12254              True   \n",
      "\n",
      "      Region_Europe  Region_Middle East  Region_North America  Region_Oceania  \\\n",
      "1             False               False                  True           False   \n",
      "3              True               False                 False           False   \n",
      "5              True               False                 False           False   \n",
      "7              True               False                 False           False   \n",
      "9              True               False                 False           False   \n",
      "...             ...                 ...                   ...             ...   \n",
      "4889          False                True                 False           False   \n",
      "4891          False               False                 False           False   \n",
      "4892          False               False                 False           False   \n",
      "4894          False               False                 False           False   \n",
      "4895          False               False                 False           False   \n",
      "\n",
      "      Region_South Asia  Region_South East Asia  Is_Holiday_Month  \n",
      "1                 False                   False                 1  \n",
      "3                 False                   False                 1  \n",
      "5                 False                   False                 1  \n",
      "7                 False                   False                 1  \n",
      "9                 False                   False                 1  \n",
      "...                 ...                     ...               ...  \n",
      "4889              False                   False                 1  \n",
      "4891               True                   False                 1  \n",
      "4892               True                   False                 1  \n",
      "4894              False                   False                 1  \n",
      "4895              False                   False                 1  \n",
      "\n",
      "[1296 rows x 17 columns]\n",
      "Updated Training set size after removing duplicates: (3672, 17)\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in the entire dataset\n",
    "duplicates = df[df.duplicated()]\n",
    "\n",
    "# Print the duplicates\n",
    "print(f\"Number of duplicate rows: {duplicates.shape[0]}\")\n",
    "print(duplicates)\n",
    "\n",
    "# If you want to drop the duplicates, you can use:\n",
    "train_df = df.drop_duplicates()\n",
    "\n",
    "# Save the dataset after removing duplicates\n",
    "train_df.to_csv(\"train_data_with_holidays.csv\", index=False)\n",
    "\n",
    "# Check the updated shape\n",
    "print(f\"Updated Training set size after removing duplicates: {train_df.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
