{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Singapore Air Traffic Class Prediction Model (TRAINING)\n",
    "\n",
    "This code builds a machine learning model to predict traffic volume classes for Singapore air travel.\n",
    "\n",
    "The model helps airlines, travel agencies, and policymakers to:\n",
    "1. Predict peak and off-peak travel periods\n",
    "2. Optimize flight schedules\n",
    "3. Allocate resources efficiently\n",
    "4. Enhance passenger experience\n",
    "\n",
    "Author: Myat Ko\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA LOADING AND EXPLORATION\n",
    "# =============================================================================\n",
    "# First, we load our dataset and examine its basic properties\n",
    "\n",
    "# Attempt to load the dataset from different possible locations\n",
    "try:\n",
    "    df = pd.read_csv(\"train_data_with_traffic_class.csv\")\n",
    "except:\n",
    "    # Try alternative paths if the file isn't found\n",
    "    try:\n",
    "        df = pd.read_csv(\"C:/Users/Myat Ko/Documents/GitHub/traveltrends/Classification/train_data_with_traffic_class.csv\")\n",
    "    except:\n",
    "        # To adjust this path based on current file structure\n",
    "        print(\"Please check the file path and try again.\")\n",
    "\n",
    "# Print dataset summary information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Number of traffic classes: {df['Traffic_Class'].nunique()}\")\n",
    "print(f\"Traffic classes: {sorted(df['Traffic_Class'].unique())}\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "if missing_values.sum() > 0:\n",
    "    print(\"\\nMissing values in dataset:\")\n",
    "    print(missing_values[missing_values > 0])\n",
    "\n",
    "# Examine the distribution of traffic classes\n",
    "traffic_class_counts = df['Traffic_Class'].value_counts().sort_index()\n",
    "print(\"\\nTraffic class distribution:\")\n",
    "for class_id, count in traffic_class_counts.items():\n",
    "    percentage = 100 * count / len(df)\n",
    "    print(f\"Class {class_id}: {count} samples ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA PREPROCESSING AND FEATURE ENGINEERING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n=== DATA PREPROCESSING AND FEATURE ENGINEERING ===\")\n",
    "\n",
    "# First, remove any columns with all NaN values\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Only drop Traffic_Class since that's our target\n",
    "drop_columns = [\"Traffic_Class\"]\n",
    "\n",
    "# Identify categorical columns (object type) and numeric columns\n",
    "categorical_columns = [col for col in df.columns if df[col].dtype == 'object' and col not in drop_columns]\n",
    "numeric_columns = [col for col in df.columns if df[col].dtype != 'object' and col not in drop_columns]\n",
    "\n",
    "print(f\"Categorical columns: {categorical_columns}\")\n",
    "print(f\"Numeric columns: {numeric_columns}\")\n",
    "\n",
    "# =============================================================================\n",
    "# KEY CHANGE: Use One-Hot Encoding instead of Label Encoding for categorical variables\n",
    "# =============================================================================\n",
    "\n",
    "# Handle categorical features with one-hot encoding\n",
    "# This prevents introducing arbitrary ordinal relationships\n",
    "if categorical_columns:\n",
    "    print(\"\\nApplying one-hot encoding to categorical columns...\")\n",
    "    \n",
    "    # First, fill missing values in categorical columns\n",
    "    for col in categorical_columns:\n",
    "        df[col] = df[col].fillna('Unknown')\n",
    "    \n",
    "    # Apply one-hot encoding\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    encoded_cats = encoder.fit_transform(df[categorical_columns])\n",
    "    \n",
    "    # Get the feature names from the encoder\n",
    "    encoded_feature_names = encoder.get_feature_names_out(categorical_columns)\n",
    "    \n",
    "    # Create a DataFrame with the encoded values\n",
    "    encoded_df = pd.DataFrame(encoded_cats, columns=encoded_feature_names, index=df.index)\n",
    "    \n",
    "    # Concatenate with the original DataFrame\n",
    "    df = pd.concat([df, encoded_df], axis=1)\n",
    "    \n",
    "    print(f\"- Created {len(encoded_feature_names)} one-hot encoded features\")\n",
    "    \n",
    "    # Track the encoded columns for later use\n",
    "    categorical_encoded = list(encoded_feature_names)\n",
    "    # Keep track of original columns to exclude from model features\n",
    "    categorical_columns_to_drop = categorical_columns.copy()\n",
    "else:\n",
    "    categorical_encoded = []\n",
    "    categorical_columns_to_drop = []\n",
    "\n",
    "# Define our base feature columns - both numeric and encoded categorical\n",
    "base_feature_columns = numeric_columns + categorical_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MODEL PIPELINE SETUP\n",
    "# =============================================================================\n",
    "# Create standardized processing pipelines to ensure consistent data handling\n",
    "# during both training and inference.\n",
    "\n",
    "print(\"\\n=== MODEL PIPELINE SETUP ===\")\n",
    "\n",
    "# Standard preprocessing pipeline for basic features\n",
    "# This ensures consistent handling of missing values and feature scaling\n",
    "preprocessing = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Fill missing values with median\n",
    "    ('scaler', StandardScaler())  # Standardize features to mean=0, std=1\n",
    "])\n",
    "\n",
    "# Enhanced preprocessing pipeline that includes polynomial feature generation\n",
    "# This creates interaction terms to capture complex relationships\n",
    "poly_preprocessing = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    # Create interaction terms between features while avoiding full polynomials\n",
    "    ('poly', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HYPERPARAMETER TUNING\n",
    "# =============================================================================\n",
    "# Find the optimal model parameters through grid search cross-validation\n",
    "# This systematically tests different combinations to find the best settings.\n",
    "\n",
    "print(\"\\n=== HYPERPARAMETER TUNING ===\")\n",
    "\n",
    "# Create a complete pipeline including preprocessing and the classifier\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor', preprocessing),\n",
    "    ('classifier', LogisticRegression(max_iter=2000, random_state=42))\n",
    "])\n",
    "\n",
    "# Define the parameter grid to search\n",
    "# These are the key hyperparameters that affect logistic regression performance\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 1, 10, 100],  # Regularization strength (lower = stronger)\n",
    "    'classifier__solver': ['lbfgs', 'newton-cg'],  # Optimization algorithm\n",
    "    'classifier__class_weight': [None, 'balanced']  # Whether to adjust for class imbalance\n",
    "}\n",
    "\n",
    "# Use stratified k-fold cross-validation to ensure representative sampling\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(\n",
    "    pipe, param_grid, cv=cv, scoring='accuracy', verbose=1, n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Performing grid search for optimal hyperparameters...\")\n",
    "# Fit the grid search to find the best parameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Display the best parameters and their performance\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid_search.best_score_))\n",
    "\n",
    "# Store the best parameters for use in our models\n",
    "best_params = grid_search.best_params_\n",
    "best_C = best_params['classifier__C']\n",
    "best_solver = best_params['classifier__solver']\n",
    "best_class_weight = best_params['classifier__class_weight']\n",
    "\n",
    "print(f\"\\nOptimal parameters: C={best_C}, solver={best_solver}, class_weight={best_class_weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MODEL COMPARISON\n",
    "# =============================================================================\n",
    "# Compare different model configurations to understand which approach works best\n",
    "# This helps identify the impact of feature engineering and hyperparameter tuning.\n",
    "\n",
    "print(\"\\n=== MODEL COMPARISON ===\")\n",
    "\n",
    "# Define three model variations to compare:\n",
    "models = {\n",
    "    # Baseline model with default hyperparameters\n",
    "    \"Base Logistic Regression\": Pipeline([\n",
    "        ('preprocessor', preprocessing),\n",
    "        ('classifier', LogisticRegression(max_iter=2000, random_state=42, solver='lbfgs'))\n",
    "    ]),\n",
    "    \n",
    "    # Model with tuned hyperparameters from grid search\n",
    "    \"Tuned Logistic Regression\": Pipeline([\n",
    "        ('preprocessor', preprocessing),\n",
    "        ('classifier', LogisticRegression(\n",
    "            C=best_C, solver=best_solver, class_weight=best_class_weight,\n",
    "            max_iter=2000, random_state=42))\n",
    "    ]),\n",
    "    \n",
    "    # Model with tuned hyperparameters AND polynomial feature interactions\n",
    "    \"Logistic with Enhanced Features\": Pipeline([\n",
    "        ('preprocessor', poly_preprocessing),\n",
    "        ('classifier', LogisticRegression(\n",
    "            C=best_C, solver=best_solver, class_weight=best_class_weight,\n",
    "            max_iter=2000, random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Function to evaluate each model and produce detailed performance metrics\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name=\"Classification Model\"):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a classification model for traffic class prediction.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : The classification model pipeline to evaluate\n",
    "    X_train, X_test : Training and test feature matrices\n",
    "    y_train, y_test : Training and test target values\n",
    "    model_name : Name of the model for reporting purposes\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    accuracy : Overall accuracy of the model\n",
    "    y_pred : Predicted classes for the test set\n",
    "    trained_model : The trained model object\n",
    "    \"\"\"\n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate overall accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Print performance summary\n",
    "    print(f\"\\n===== {model_name} =====\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Generate detailed classification metrics by class\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Create confusion matrix to visualize prediction patterns\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Plot confusion matrix as a heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.ylabel('True Traffic Class')\n",
    "    plt.xlabel('Predicted Traffic Class')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return accuracy, y_pred, model\n",
    "\n",
    "# Storage for results and trained models\n",
    "results = {}\n",
    "models_trained = {}\n",
    "\n",
    "# Loop through each model and evaluate its performance\n",
    "for name, model in models.items():\n",
    "    # Evaluate the model using the same X_train and X_test for all models\n",
    "    accuracy, y_pred, trained_model = evaluate_model(\n",
    "        model, X_train, X_test, y_train, y_test, name\n",
    "    )\n",
    "    results[name] = accuracy\n",
    "    models_trained[name] = trained_model\n",
    "\n",
    "# Print comparison of model accuracies, sorted from best to worst\n",
    "print(\"\\n=== FINAL RESULTS ===\")\n",
    "for name, accuracy in sorted(results.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{name}: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CREATE ADDITIONAL ADVANCED FEATURES\n",
    "# =============================================================================\n",
    "print(\"\\n=== CREATING ADVANCED FEATURE COMBINATIONS ===\")\n",
    "\n",
    "# 1. Calculate traffic ratios to capture proportional patterns\n",
    "if all(col in df.columns for col in ['Arrivals', 'Departures', 'Total_Traffic']):\n",
    "    print(\"Creating traffic ratio features...\")\n",
    "    # Avoid division by zero\n",
    "    df['Arrivals_Ratio'] = df['Arrivals'] / (df['Total_Traffic'] + 1)\n",
    "    df['Departures_Ratio'] = df['Departures'] / (df['Total_Traffic'] + 1)\n",
    "    print(\"- Created Arrivals_Ratio and Departures_Ratio\")\n",
    "\n",
    "# 2. Create month-based seasonal indicators\n",
    "if 'Month' in df.columns:\n",
    "    print(\"Creating seasonal indicators...\")\n",
    "    # Create season indicators (Northern hemisphere)\n",
    "    # Winter: Dec-Feb (12, 1, 2), Spring: Mar-May (3, 4, 5), \n",
    "    # Summer: Jun-Aug (6, 7, 8), Fall: Sep-Nov (9, 10, 11)\n",
    "    df['Winter'] = df['Month'].isin([12, 1, 2]).astype(int)\n",
    "    df['Spring'] = df['Month'].isin([3, 4, 5]).astype(int)\n",
    "    df['Summer'] = df['Month'].isin([6, 7, 8]).astype(int)\n",
    "    df['Fall'] = df['Month'].isin([9, 10, 11]).astype(int)\n",
    "    print(\"- Created seasonal indicators (Winter, Spring, Summer, Fall)\")\n",
    "\n",
    "# 3. Create holiday-traffic interaction features\n",
    "if 'Total Holidays' in df.columns and 'Total_Traffic' in df.columns:\n",
    "    print(\"Creating holiday interaction features...\")\n",
    "    df['Holiday_Traffic_Ratio'] = df['Total Holidays'] / (df['Total_Traffic'] + 1)\n",
    "    df['Holiday_Present'] = (df['Total Holidays'] > 0).astype(int)\n",
    "    print(\"- Created Holiday_Traffic_Ratio and Holiday_Present\")\n",
    "\n",
    "# 4. Calculate logarithmic transformations of key metrics\n",
    "# This can help with skewed distributions\n",
    "for col in ['Arrivals', 'Departures', 'Total_Traffic']:\n",
    "    if col in df.columns:\n",
    "        df[f'Log_{col}'] = np.log1p(df[col])  # log1p handles zeros\n",
    "        print(f\"- Created Log_{col}\")\n",
    "\n",
    "# 5. Create month and inflation interaction\n",
    "if all(col in df.columns for col in ['Month', 'Inflation']):\n",
    "    print(\"Creating month-inflation interactions...\")\n",
    "    for month in range(1, 13):\n",
    "        df[f'Month{month}_Inflation'] = ((df['Month'] == month) * df['Inflation']).astype(float)\n",
    "    print(\"- Created month-specific inflation features\")\n",
    "\n",
    "# 6. Month-Holiday interaction\n",
    "if all(col in df.columns for col in ['Month', 'Total Holidays']):\n",
    "    print(\"Creating month-holiday interactions...\")\n",
    "    for month in range(1, 13):\n",
    "        df[f'Month{month}_Holidays'] = ((df['Month'] == month) * df['Total Holidays']).astype(float)\n",
    "    print(\"- Created month-specific holiday features\")\n",
    "\n",
    "# Add all new features to our feature list\n",
    "new_features = [col for col in df.columns if col not in base_feature_columns \n",
    "                and col not in categorical_columns_to_drop\n",
    "                and col not in drop_columns\n",
    "                and col != 'Traffic_Class']\n",
    "\n",
    "# Combine base and new features\n",
    "all_features = base_feature_columns + new_features\n",
    "\n",
    "# Print new feature summary\n",
    "print(f\"\\nCreated {len(new_features)} new engineered features:\")\n",
    "print(\", \".join(new_features))\n",
    "\n",
    "# Define X and y, dropping original categorical columns\n",
    "X = df[all_features].copy()\n",
    "y = df['Traffic_Class'].copy()\n",
    "\n",
    "# Print final feature information\n",
    "print(f\"\\nTotal features for modeling: {len(all_features)}\")\n",
    "print(f\"- {len(base_feature_columns)} base features\")\n",
    "print(f\"- {len(new_features)} engineered features\")\n",
    "\n",
    "# Split data into training (70%) and testing (30%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Check for any remaining missing values in features\n",
    "missing_in_features = X.isnull().sum()\n",
    "if missing_in_features.sum() > 0:\n",
    "    print(\"\\nMissing values in feature matrix:\")\n",
    "    print(missing_in_features[missing_in_features > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MODEL PIPELINE SETUP\n",
    "# =============================================================================\n",
    "print(\"\\n=== MODEL PIPELINE SETUP ===\")\n",
    "\n",
    "# Create a preprocessing pipeline that handles missing values and scaling\n",
    "preprocessing = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Enhanced features pipeline with polynomial features\n",
    "poly_preprocessing = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HYPERPARAMETER TUNING\n",
    "# =============================================================================\n",
    "print(\"\\n=== HYPERPARAMETER TUNING ===\")\n",
    "\n",
    "# Create pipeline with preprocessing and classifier\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor', preprocessing),\n",
    "    ('classifier', LogisticRegression(max_iter=2000, random_state=42))\n",
    "])\n",
    "\n",
    "# Parameter grid for tuning\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 1, 10, 100],\n",
    "    'classifier__solver': ['lbfgs', 'newton-cg'],\n",
    "    'classifier__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# Stratified cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(\n",
    "    pipe, param_grid, cv=cv, scoring='accuracy', verbose=1, n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Performing grid search for optimal hyperparameters...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid_search.best_score_))\n",
    "\n",
    "# Store best parameters\n",
    "best_params = grid_search.best_params_\n",
    "best_C = best_params['classifier__C']\n",
    "best_solver = best_params['classifier__solver']\n",
    "best_class_weight = best_params['classifier__class_weight']\n",
    "\n",
    "print(f\"\\nOptimal parameters: C={best_C}, solver={best_solver}, class_weight={best_class_weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MODEL COMPARISON\n",
    "# =============================================================================\n",
    "print(\"\\n=== MODEL COMPARISON ===\")\n",
    "\n",
    "# Define the three models to compare\n",
    "models = {\n",
    "    \"Base Logistic Regression\": Pipeline([\n",
    "        ('preprocessor', preprocessing),\n",
    "        ('classifier', LogisticRegression(max_iter=2000, random_state=42, solver='lbfgs'))\n",
    "    ]),\n",
    "    \"Tuned Logistic Regression\": Pipeline([\n",
    "        ('preprocessor', preprocessing),\n",
    "        ('classifier', LogisticRegression(\n",
    "            C=best_C, solver=best_solver, class_weight=best_class_weight,\n",
    "            max_iter=2000, random_state=42))\n",
    "    ]),\n",
    "    \"Logistic with Enhanced Features\": Pipeline([\n",
    "        ('preprocessor', poly_preprocessing),\n",
    "        ('classifier', LogisticRegression(\n",
    "            C=best_C, solver=best_solver, class_weight=best_class_weight,\n",
    "            max_iter=2000, random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Function to evaluate each model\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name=\"Classification Model\"):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a classification model for traffic class prediction.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : The classification model pipeline to evaluate\n",
    "    X_train, X_test : Training and test feature matrices\n",
    "    y_train, y_test : Training and test target values\n",
    "    model_name : Name of the model for reporting purposes\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    accuracy : Overall accuracy of the model\n",
    "    y_pred : Predicted classes for the test set\n",
    "    trained_model : The trained model object\n",
    "    \"\"\"\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n===== {model_name} =====\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Generate detailed classification metrics\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.ylabel('True Traffic Class')\n",
    "    plt.xlabel('Predicted Traffic Class')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return accuracy, y_pred, model\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "models_trained = {}\n",
    "\n",
    "# Loop through each model and evaluate\n",
    "for name, model in models.items():\n",
    "    # Evaluate the model using the same X_train and X_test for all models\n",
    "    accuracy, y_pred, trained_model = evaluate_model(\n",
    "        model, X_train, X_test, y_train, y_test, name\n",
    "    )\n",
    "    results[name] = accuracy\n",
    "    models_trained[name] = trained_model\n",
    "\n",
    "# Print comparison of model accuracies\n",
    "print(\"\\n=== FINAL RESULTS ===\")\n",
    "for name, accuracy in sorted(results.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{name}: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# BEST MODEL ANALYSIS\n",
    "# =============================================================================\n",
    "print(\"\\n=== BEST MODEL ANALYSIS ===\")\n",
    "\n",
    "# Identify the model with the highest accuracy\n",
    "best_model_name = max(results, key=results.get)\n",
    "print(f\"Best model: {best_model_name} (Accuracy: {results[best_model_name]:.4f})\")\n",
    "\n",
    "# Get the best trained model\n",
    "best_model = models_trained[best_model_name]\n",
    "\n",
    "# Get predictions\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy per class\n",
    "class_accuracy = {}\n",
    "for class_id in np.unique(y_test):\n",
    "    class_mask = (y_test == class_id)\n",
    "    class_correct = (y_pred_best[class_mask] == class_id).sum()\n",
    "    class_total = class_mask.sum()\n",
    "    class_accuracy[class_id] = class_correct / class_total\n",
    "\n",
    "print(\"\\nAccuracy by Traffic Class:\")\n",
    "for class_id, acc in sorted(class_accuracy.items()):\n",
    "    print(f\"Class {class_id}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEATURE IMPORTANCE ANALYSIS\n",
    "# =============================================================================\n",
    "print(\"\\n=== FEATURE IMPORTANCE ANALYSIS ===\")\n",
    "\n",
    "# For logistic regression, we can examine coefficients\n",
    "if \"Logistic\" in best_model_name:\n",
    "    # Get the classifier from the pipeline\n",
    "    classifier = best_model.named_steps['classifier']\n",
    "    \n",
    "    # Get feature names after preprocessing\n",
    "    if best_model_name == \"Logistic with Enhanced Features\":\n",
    "        # For polynomial features, we need to get the transformed feature names\n",
    "        poly = best_model.named_steps['preprocessor'].named_steps['poly']\n",
    "        feature_names = poly.get_feature_names_out(input_features=all_features)\n",
    "    else:\n",
    "        feature_names = all_features\n",
    "    \n",
    "    # Get coefficients\n",
    "    coefficients = classifier.coef_\n",
    "    \n",
    "    # For multiclass, average the absolute coefficient values across classes\n",
    "    importance = np.abs(coefficients).mean(axis=0)\n",
    "    \n",
    "    # Create a DataFrame for visualization\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importance\n",
    "    })\n",
    "    feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Display top 20 features\n",
    "    print(\"\\nTop 20 most important features:\")\n",
    "    for i, (feature, importance) in enumerate(zip(feature_importance['Feature'][:20], \n",
    "                                                feature_importance['Importance'][:20])):\n",
    "        print(f\"{i+1}. {feature}: {importance:.4f}\")\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance.head(20))\n",
    "    plt.title('Top 20 Most Important Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SAVE THE BEST MODEL\n",
    "# =============================================================================\n",
    "# Create directory if it doesn't exist\n",
    "model_dir = 'models'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Save the best model\n",
    "best_model_file = os.path.join(model_dir, 'traffic_class_predictor_onehot.pkl')\n",
    "with open(best_model_file, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'model': best_model,\n",
    "        'features': all_features,\n",
    "        'encoder': encoder if 'encoder' in locals() else None\n",
    "    }, f)\n",
    "\n",
    "print(f\"\\nBest model saved to {best_model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# INSIGHTS AND RECOMMENDATIONS\n",
    "# =============================================================================\n",
    "# Summarize key findings and provide actionable recommendations\n",
    "\n",
    "print(\"\\n=== TRAFFIC CLASS PREDICTION INSIGHTS ===\")\n",
    "print(\"The model predicts traffic volume classes for Singapore air travel with improved\")\n",
    "print(\"accuracy through advanced feature engineering and restored traffic metrics.\")\n",
    "print(\"\\nKey findings:\")\n",
    "print(\"1. Restoring key traffic features (Total_Traffic, Arrivals, Departures) and\")\n",
    "print(\"   creating advanced feature combinations significantly improved model performance.\")\n",
    "print(\"2. Seasonal patterns, holiday interactions, and traffic ratios provide valuable\")\n",
    "print(\"   predictive information for identifying different traffic classes.\")\n",
    "print(\"3. The model achieves substantially better results with this enhanced approach.\")\n",
    "print(\"\\nRecommendations for stakeholders:\")\n",
    "print(\"1. Airlines should focus on the most predictive features identified in this model\")\n",
    "print(\"   when optimizing flight schedules.\")\n",
    "print(\"2. The added seasonal and holiday interaction features can help travel agencies\")\n",
    "print(\"   better target their promotions during specific time periods.\")\n",
    "print(\"3. Airport resource allocation can be improved by monitoring these key indicators,\")\n",
    "print(\"   particularly the traffic ratios and holiday-related features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Singapore Air Traffic Class Prediction Model with One-Hot Encoding\n",
    "\n",
    "This code builds and evaluates a machine learning model to predict traffic classes based on\n",
    "travel data to and from Singapore. It implements advanced feature engineering with one-hot\n",
    "encoding for categorical variables instead of label encoding.\n",
    "\n",
    "Author: Myat Ko\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "import shap\n",
    "\n",
    "# =============================================================================\n",
    "# DATA LOADING AND EXPLORATION\n",
    "# =============================================================================\n",
    "# First, we load our dataset and examine its basic properties\n",
    "\n",
    "# Attempt to load the dataset from different possible locations\n",
    "try:\n",
    "    df = pd.read_csv(\"train_data_with_traffic_class.csv\")\n",
    "except:\n",
    "    # Try alternative paths if the file isn't found\n",
    "    try:\n",
    "        df = pd.read_csv(\"C:/Users/Acer/Dropbox/PC (2)/Documents/Github/traveltrends/Classification/train_data_with_traffic_class.csv\")\n",
    "    except:\n",
    "        # To adjust this path based on current file structure\n",
    "        print(\"Please check the file path and try again.\")\n",
    "\n",
    "# Print dataset summary information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Number of traffic classes: {df['Traffic_Class'].nunique()}\")\n",
    "print(f\"Traffic classes: {sorted(df['Traffic_Class'].unique())}\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "if missing_values.sum() > 0:\n",
    "    print(\"\\nMissing values in dataset:\")\n",
    "    print(missing_values[missing_values > 0])\n",
    "\n",
    "# Examine the distribution of traffic classes\n",
    "traffic_class_counts = df['Traffic_Class'].value_counts().sort_index()\n",
    "print(\"\\nTraffic class distribution:\")\n",
    "for class_id, count in traffic_class_counts.items():\n",
    "    percentage = 100 * count / len(df)\n",
    "    print(f\"Class {class_id}: {count} samples ({percentage:.1f}%)\")\n",
    "\n",
    "# =============================================================================\n",
    "# DATA PREPROCESSING AND FEATURE ENGINEERING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n=== DATA PREPROCESSING AND FEATURE ENGINEERING ===\")\n",
    "\n",
    "# First, remove any columns with all NaN values\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Drop Unnecessary features since we are finding traffic_class(our target)\n",
    "drop_columns = [\"Total_Traffic\", \"Departures\", \"Arrivals\", \"Traffic_Class\", \"Month\"]\n",
    "\n",
    "# Identify categorical columns (object type) and numeric columns\n",
    "categorical_columns = [col for col in df.columns if df[col].dtype == 'object' and col not in drop_columns]\n",
    "numeric_columns = [col for col in df.columns if df[col].dtype != 'object' and col not in drop_columns]\n",
    "\n",
    "print(f\"Categorical columns: {categorical_columns}\")\n",
    "print(f\"Numeric columns: {numeric_columns}\")\n",
    "\n",
    "# =============================================================================\n",
    "# KEY CHANGE: Use One-Hot Encoding instead of Label Encoding for categorical variables\n",
    "# =============================================================================\n",
    "\n",
    "# Handle categorical features with one-hot encoding\n",
    "# This prevents introducing arbitrary ordinal relationships\n",
    "if categorical_columns:\n",
    "    print(\"\\nApplying one-hot encoding to categorical columns...\")\n",
    "    \n",
    "    # First, fill missing values in categorical columns\n",
    "    for col in categorical_columns:\n",
    "        df[col] = df[col].fillna('Unknown')\n",
    "    \n",
    "    # Apply one-hot encoding\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    encoded_cats = encoder.fit_transform(df[categorical_columns])\n",
    "    \n",
    "    # Get the feature names from the encoder\n",
    "    encoded_feature_names = encoder.get_feature_names_out(categorical_columns)\n",
    "    \n",
    "    # Create a DataFrame with the encoded values\n",
    "    encoded_df = pd.DataFrame(encoded_cats, columns=encoded_feature_names, index=df.index)\n",
    "    \n",
    "    # Concatenate with the original DataFrame\n",
    "    df = pd.concat([df, encoded_df], axis=1)\n",
    "    \n",
    "    print(f\"- Created {len(encoded_feature_names)} one-hot encoded features\")\n",
    "    \n",
    "    # Track the encoded columns for later use\n",
    "    categorical_encoded = list(encoded_feature_names)\n",
    "    # Keep track of original columns to exclude from model features\n",
    "    categorical_columns_to_drop = categorical_columns.copy()\n",
    "else:\n",
    "    categorical_encoded = []\n",
    "    categorical_columns_to_drop = []\n",
    "\n",
    "# Define our base feature columns - both numeric and encoded categorical\n",
    "base_feature_columns = numeric_columns + categorical_encoded\n",
    "\n",
    "# =============================================================================\n",
    "# CREATE ADDITIONAL ADVANCED FEATURES\n",
    "# =============================================================================\n",
    "# print(\"\\n=== CREATING ADVANCED FEATURE COMBINATIONS ===\")\n",
    "\n",
    "# Add all new features to our feature list\n",
    "new_features = [col for col in df.columns if col not in base_feature_columns \n",
    "                and col not in categorical_columns_to_drop\n",
    "                and col not in drop_columns\n",
    "                and col != 'Traffic_Class']\n",
    "\n",
    "# Combine base and new features\n",
    "all_features = base_feature_columns + new_features\n",
    "\n",
    "# Print new feature summary\n",
    "print(f\"\\nCreated {len(new_features)} new engineered features:\")\n",
    "print(\", \".join(new_features))\n",
    "\n",
    "# Define X and y, dropping original categorical columns\n",
    "X = df[all_features].copy()\n",
    "y = df['Traffic_Class'].copy()\n",
    "\n",
    "# Print final feature information\n",
    "print(f\"\\nTotal features for modeling: {len(all_features)}\")\n",
    "print(f\"- {len(base_feature_columns)} base features\")\n",
    "print(f\"- {len(new_features)} engineered features\")\n",
    "\n",
    "#df.to_csv('train_data_with_traffic_class_merged.csv', index=False)\n",
    "\n",
    "# =============================================================================\n",
    "# TRAIN-VALIDATION SPLIT\n",
    "# =============================================================================\n",
    "print(\"\\n=== TRAIN-VALIDATION SPLIT ===\")\n",
    "\n",
    "# Split into train (70%) and validation (30%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "\n",
    "# Check for any remaining missing values in features\n",
    "missing_in_features = X.isnull().sum()\n",
    "if missing_in_features.sum() > 0:\n",
    "    print(\"\\nMissing values in feature matrix:\")\n",
    "    print(missing_in_features[missing_in_features > 0])\n",
    "\n",
    "# =============================================================================\n",
    "# MODEL PIPELINE SETUP\n",
    "# =============================================================================\n",
    "print(\"\\n=== MODEL PIPELINE SETUP ===\")\n",
    "\n",
    "# Create a preprocessing pipeline that handles missing values and scaling\n",
    "preprocessing = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Enhanced features pipeline with polynomial features\n",
    "poly_preprocessing = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False))\n",
    "])\n",
    "\n",
    "# =============================================================================\n",
    "# HYPERPARAMETER TUNING\n",
    "# =============================================================================\n",
    "print(\"\\n=== HYPERPARAMETER TUNING ===\")\n",
    "\n",
    "# Create pipeline with preprocessing and classifier\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor', preprocessing),\n",
    "    ('classifier', LogisticRegression(max_iter=2000, random_state=42))\n",
    "])\n",
    "\n",
    "# Parameter grid for tuning\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 1, 10, 100],\n",
    "    'classifier__solver': ['lbfgs', 'newton-cg'],\n",
    "    'classifier__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# Stratified cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform grid search on the training data\n",
    "grid_search = GridSearchCV(\n",
    "    pipe, param_grid, cv=cv, scoring='accuracy', verbose=1, n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Performing grid search for optimal hyperparameters...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid_search.best_score_))\n",
    "\n",
    "# Store best parameters\n",
    "best_params = grid_search.best_params_\n",
    "best_C = best_params['classifier__C']\n",
    "best_solver = best_params['classifier__solver']\n",
    "best_class_weight = best_params['classifier__class_weight']\n",
    "\n",
    "print(f\"\\nOptimal parameters: C={best_C}, solver={best_solver}, class_weight={best_class_weight}\")\n",
    "\n",
    "# =============================================================================\n",
    "# MODEL COMPARISON WITH VALIDATION SET\n",
    "# =============================================================================\n",
    "print(\"\\n=== MODEL COMPARISON WITH VALIDATION SET ===\")\n",
    "\n",
    "# Define the three models to compare\n",
    "models = {\n",
    "    \"Base Logistic Regression\": Pipeline([\n",
    "        ('preprocessor', preprocessing),\n",
    "        ('classifier', LogisticRegression(max_iter=2000, random_state=42, solver='lbfgs'))\n",
    "    ]),\n",
    "    \"Tuned Logistic Regression\": Pipeline([\n",
    "        ('preprocessor', preprocessing),\n",
    "        ('classifier', LogisticRegression(\n",
    "            C=best_C, solver=best_solver, class_weight=best_class_weight,\n",
    "            max_iter=2000, random_state=42))\n",
    "    ]),\n",
    "    \"Logistic with Enhanced Features\": Pipeline([\n",
    "        ('preprocessor', poly_preprocessing),\n",
    "        ('classifier', LogisticRegression(\n",
    "            C=best_C, solver=best_solver, class_weight=best_class_weight,\n",
    "            max_iter=2000, random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Function to evaluate each model\n",
    "def evaluate_model(model, X_train, X_val, y_train, y_val, model_name=\"Classification Model\"):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a classification model using training and validation sets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : The classification model pipeline to evaluate\n",
    "    X_train, X_val : Training and validation feature matrices\n",
    "    y_train, y_val : Training and validation target values\n",
    "    model_name : Name of the model for reporting purposes\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    metrics : Dictionary containing train and validation accuracy\n",
    "    y_pred_val : Predicted classes for the validation set\n",
    "    trained_model : The trained model object\n",
    "    \"\"\"\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on train and validation sets\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    val_accuracy = accuracy_score(y_val, y_pred_val)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n===== {model_name} =====\")\n",
    "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    # Check for overfitting\n",
    "    train_val_diff = train_accuracy - val_accuracy\n",
    "    print(f\"Train-Validation Accuracy Gap: {train_val_diff:.4f}\")\n",
    "    \n",
    "    if train_val_diff > 0.05:\n",
    "        print(\"WARNING: Possible overfitting detected (Train-Val gap > 5%)\")\n",
    "    \n",
    "    # Generate detailed classification metrics on validation set\n",
    "    print(\"\\nValidation Classification Report:\")\n",
    "    print(classification_report(y_val, y_pred_val))\n",
    "    \n",
    "    # Create confusion matrix for validation set\n",
    "    cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Validation Confusion Matrix - {model_name}')\n",
    "    plt.ylabel('True Traffic Class')\n",
    "    plt.xlabel('Predicted Traffic Class')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return metrics and model\n",
    "    metrics = {\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'train_val_diff': train_val_diff\n",
    "    }\n",
    "    \n",
    "    return metrics, y_pred_val, model\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "models_trained = {}\n",
    "\n",
    "# Loop through each model and evaluate\n",
    "for name, model in models.items():\n",
    "    # Evaluate the model using train and validation sets\n",
    "    metrics, y_pred_val, trained_model = evaluate_model(\n",
    "        model, X_train, X_val, y_train, y_val, name\n",
    "    )\n",
    "    results[name] = metrics\n",
    "    models_trained[name] = trained_model\n",
    "\n",
    "# Print comparison of model accuracies\n",
    "print(\"\\n=== FINAL RESULTS ===\")\n",
    "print(\"Model                      Train Acc  Val Acc   Train-Val Gap\")\n",
    "print(\"-------------------------  ---------  --------  -------------\")\n",
    "for name, metrics in sorted(results.items(), key=lambda x: x[1]['val_accuracy'], reverse=True):\n",
    "    print(f\"{name[:25]:<25}  {metrics['train_accuracy']:.4f}    {metrics['val_accuracy']:.4f}    {metrics['train_val_diff']:.4f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# BEST MODEL ANALYSIS\n",
    "# =============================================================================\n",
    "print(\"\\n=== BEST MODEL ANALYSIS ===\")\n",
    "\n",
    "# Get the best model based on validation accuracy\n",
    "best_model_name = sorted(results.items(), key=lambda x: x[1]['val_accuracy'], reverse=True)[0][0]\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "print(f\"Validation Accuracy: {results[best_model_name]['val_accuracy']:.4f}\")\n",
    "\n",
    "# Get the best trained model\n",
    "best_model = models_trained[best_model_name]\n",
    "\n",
    "# Get validation predictions\n",
    "y_pred_val = best_model.predict(X_val)\n",
    "\n",
    "# Calculate accuracy per class\n",
    "class_accuracy = {}\n",
    "for class_id in np.unique(y_val):\n",
    "    class_mask = (y_val == class_id)\n",
    "    class_correct = (y_pred_val[class_mask] == class_id).sum()\n",
    "    class_total = class_mask.sum()\n",
    "    class_accuracy[class_id] = class_correct / class_total\n",
    "\n",
    "print(\"\\nAccuracy by Traffic Class:\")\n",
    "for class_id, acc in sorted(class_accuracy.items()):\n",
    "    print(f\"Class {class_id}: {acc:.4f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# FEATURE IMPORTANCE ANALYSIS\n",
    "# =============================================================================\n",
    "print(\"\\n=== FEATURE IMPORTANCE ANALYSIS ===\")\n",
    "\n",
    "# For logistic regression, we can examine coefficients\n",
    "if \"Logistic\" in best_model_name:\n",
    "    # Get the classifier from the pipeline\n",
    "    classifier = best_model.named_steps['classifier']\n",
    "    \n",
    "    # Get feature names after preprocessing\n",
    "    if best_model_name == \"Logistic with Enhanced Features\":\n",
    "        # For polynomial features, we need to get the transformed feature names\n",
    "        poly = best_model.named_steps['preprocessor'].named_steps['poly']\n",
    "        feature_names = poly.get_feature_names_out(input_features=all_features)\n",
    "    else:\n",
    "        feature_names = all_features\n",
    "    \n",
    "    # Get coefficients\n",
    "    coefficients = classifier.coef_\n",
    "    \n",
    "    # For multiclass, average the absolute coefficient values across classes\n",
    "    importance = np.abs(coefficients).mean(axis=0)\n",
    "    \n",
    "    # Create a DataFrame for visualization\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importance\n",
    "    })\n",
    "    feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Display top 20 features\n",
    "    print(\"\\nTop 20 most important features:\")\n",
    "    for i, (feature, importance) in enumerate(zip(feature_importance['Feature'][:20], \n",
    "                                                feature_importance['Importance'][:20])):\n",
    "        print(f\"{i+1}. {feature}: {importance:.4f}\")\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance.head(20))\n",
    "    plt.title('Top 20 Most Important Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LOADING TEST DATA ===\n",
      "Test dataset shape: (449, 11)\n",
      "Test dataset contains 'Traffic_Class' column. Will evaluate model performance.\n",
      "\n",
      "=== LOADING TRAINED MODELS & ENCODERS ===\n",
      "Loaded OneHotEncoder from file.\n",
      "Processed test data shape: (449, 23)\n",
      "Features: ['Year', 'Total Holidays', 'Inflation', 'Month_sin', 'Month_cos', 'Country_Europe', 'Country_France', 'Country_Germany', 'Country_Hong Kong', 'Country_Indonesia', 'Country_Japan', 'Country_Mainland China', 'Country_Malaysia', 'Country_Middle East', 'Country_North America', 'Country_North East Asia', 'Country_Oceania', 'Country_Philippines', 'Country_South Asia', 'Country_South East Asia', 'Country_Thailand', 'Country_United Kingdom', 'Country_Vietnam']\n",
      "\n",
      "=== LOADING TRAINED MODELS ===\n",
      "One or more model files not found. Please ensure models have been trained and saved.\n",
      "\n",
      "=== MAKING PREDICTIONS WITH ALL MODELS ===\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'models_trained' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 194\u001b[39m\n\u001b[32m    191\u001b[39m results = {}\n\u001b[32m    193\u001b[39m \u001b[38;5;66;03m# Test each model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodels_trained\u001b[49m.items():\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    196\u001b[39m         y_pred = predict_and_evaluate(model, X_test_processed, y_test, name)\n",
      "\u001b[31mNameError\u001b[39m: name 'models_trained' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# =============================================================================\n",
    "# TEST DATA LOADING\n",
    "# =============================================================================\n",
    "print(\"\\n=== LOADING TEST DATA ===\")\n",
    "\n",
    "# Attempt to load the test dataset\n",
    "try:\n",
    "    test_df = pd.read_csv(\"test_data.csv\")\n",
    "    print(f\"Test dataset shape: {test_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    # Try alternative paths if the file isn't found\n",
    "    try:\n",
    "        test_df = pd.read_csv(\"C:/Users/Acer/Dropbox/PC (2)/Documents/Github/traveltrends/Classification/test_data_with_traffic_class.csv\")\n",
    "        print(f\"Test dataset shape: {test_df.shape}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Test data file not found. Please check the file path and try again.\")\n",
    "        exit()\n",
    "\n",
    "# Check if the test dataset has the target variable\n",
    "has_target = 'Traffic_Class' in test_df.columns\n",
    "if has_target:\n",
    "    print(\"Test dataset contains 'Traffic_Class' column. Will evaluate model performance.\")\n",
    "    X_test = test_df.drop('Traffic_Class', axis=1)\n",
    "    y_test = test_df['Traffic_Class']\n",
    "else:\n",
    "    print(\"Test dataset does not contain 'Traffic_Class' column. Will only generate predictions.\")\n",
    "    X_test = test_df.copy()\n",
    "    y_test = None\n",
    "\n",
    "# =============================================================================\n",
    "# LOAD TRAINED MODELS\n",
    "# =============================================================================\n",
    "print(\"\\n=== LOADING TRAINED MODELS ===\")\n",
    "\n",
    "# Get the trained models from the previous execution\n",
    "# These should be the models defined in the 'models_trained' dictionary\n",
    "models_trained = {\n",
    "    \"Base Logistic Regression\": models_trained[\"Base Logistic Regression\"], \n",
    "    \"Tuned Logistic Regression\": models_trained[\"Tuned Logistic Regression\"],\n",
    "    \"Logistic with Enhanced Features\": models_trained[\"Logistic with Enhanced Features\"]\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# PREDICTION FUNCTION\n",
    "# =============================================================================\n",
    "def predict_and_evaluate(model, X_test, y_test=None, model_name=\"Classification Model\"):\n",
    "    \"\"\"\n",
    "    Makes predictions using the trained model and evaluates if target is available.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : The trained classification model\n",
    "    X_test : Test feature matrix\n",
    "    y_test : Test target values (optional)\n",
    "    model_name : Name of the model for reporting purposes\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    y_pred : Predicted classes for the test set\n",
    "    \"\"\"\n",
    "    print(f\"\\n===== {model_name} =====\")\n",
    "    \n",
    "    # Make predictions\n",
    "    try:\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(f\"Successfully generated predictions for {len(y_pred)} samples\")\n",
    "        \n",
    "        # If we have target values, evaluate the model\n",
    "        if y_test is not None:\n",
    "            test_accuracy = accuracy_score(y_test, y_pred)\n",
    "            print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "            \n",
    "            # Generate detailed classification metrics\n",
    "            print(\"\\nTest Classification Report:\")\n",
    "            print(classification_report(y_test, y_pred))\n",
    "            \n",
    "            # Create confusion matrix\n",
    "            cm_test = confusion_matrix(y_test, y_pred)\n",
    "            \n",
    "            # Plot confusion matrix\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues')\n",
    "            plt.title(f'Test Confusion Matrix - {model_name}')\n",
    "            plt.ylabel('True Traffic Class')\n",
    "            plt.xlabel('Predicted Traffic Class')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{model_name.replace(\" \", \"_\")}_confusion_matrix.png')\n",
    "            plt.show()\n",
    "            \n",
    "            # Calculate accuracy per class\n",
    "            class_accuracy = {}\n",
    "            for class_id in np.unique(y_test):\n",
    "                class_mask = (y_test == class_id)\n",
    "                class_correct = (y_pred[class_mask] == class_id).sum()\n",
    "                class_total = class_mask.sum()\n",
    "                class_accuracy[class_id] = class_correct / class_total\n",
    "            \n",
    "            print(\"\\nAccuracy by Traffic Class:\")\n",
    "            for class_id, acc in sorted(class_accuracy.items()):\n",
    "                print(f\"Class {class_id}: {acc:.4f}\")\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# =============================================================================\n",
    "# MAKE PREDICTIONS WITH ALL MODELS\n",
    "# =============================================================================\n",
    "print(\"\\n=== MAKING PREDICTIONS WITH ALL MODELS ===\")\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Test each model\n",
    "for name, model in models_trained.items():\n",
    "    try:\n",
    "        y_pred = predict_and_evaluate(model, X_test, y_test, name)\n",
    "        results[name] = y_pred\n",
    "        \n",
    "        # Save predictions to CSV\n",
    "        if y_pred is not None:\n",
    "            predictions_df = pd.DataFrame({\n",
    "                'Predicted_Traffic_Class': y_pred\n",
    "            })\n",
    "            \n",
    "            # If we have original data, include it in the output\n",
    "            if has_target:\n",
    "                for col in test_df.columns:\n",
    "                    if col != 'Traffic_Class':\n",
    "                        predictions_df[col] = test_df[col]\n",
    "                predictions_df['True_Traffic_Class'] = y_test\n",
    "            else:\n",
    "                for col in test_df.columns:\n",
    "                    predictions_df[col] = test_df[col]\n",
    "            \n",
    "            # Save to CSV\n",
    "            output_filename = f'{name.replace(\" \", \"_\")}_predictions.csv'\n",
    "            predictions_df.to_csv(output_filename, index=False)\n",
    "            print(f\"Predictions saved to {output_filename}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing model {name}: {str(e)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# COMPARE MODEL PERFORMANCE\n",
    "# =============================================================================\n",
    "if has_target:\n",
    "    print(\"\\n=== TEST PERFORMANCE COMPARISON ===\")\n",
    "    print(\"Model                      Test Accuracy\")\n",
    "    print(\"-------------------------  -------------\")\n",
    "    \n",
    "    model_accuracies = {}\n",
    "    for name, y_pred in results.items():\n",
    "        if y_pred is not None:\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            model_accuracies[name] = accuracy\n",
    "    \n",
    "    # Sort by accuracy\n",
    "    for name, accuracy in sorted(model_accuracies.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{name[:25]:<25}  {accuracy:.4f}\")\n",
    "    \n",
    "    # Find the best model\n",
    "    best_model_name = max(model_accuracies.items(), key=lambda x: x[1])[0]\n",
    "    print(f\"\\nBest model on test data: {best_model_name}\")\n",
    "    print(f\"Test Accuracy: {model_accuracies[best_model_name]:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\n=== TESTING COMPLETE ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
