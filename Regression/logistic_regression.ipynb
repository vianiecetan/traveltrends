{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"merged_flight_train_with_holidays.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "df['Year'] = df['Month (YYYY-MM)'].apply(lambda x: int(x.split('-')[0]))\n",
    "df['Month'] = df['Month (YYYY-MM)'].apply(lambda x: int(x.split('-')[1]))\n",
    "df.drop(columns=['Month (YYYY-MM)'], inplace=True)\n",
    "\n",
    "# For classification, we need to create target variables that represent classes\n",
    "# let's say we want to classify if arrivals are above median (high) or below (low)\n",
    "arrivals_median = df['Arrivals'].median()\n",
    "df['High_Arrivals'] = (df['Arrivals'] > arrivals_median).astype(int)\n",
    "\n",
    "departures_median = df['Departures'].median()\n",
    "df['High_Departures'] = (df['Departures'] > departures_median).astype(int)\n",
    "\n",
    "# Model 1: Predict if Arrivals will be high\n",
    "# Features: 'Country', 'No of holidays', 'Year', 'Month', 'Departures'\n",
    "X_arrivals = df[['No of holidays', 'Year', 'Month', 'Departures']]\n",
    "X_arrivals = pd.concat([X_arrivals, pd.get_dummies(df['Country'], prefix='Country', drop_first=True)], axis=1)\n",
    "y_arrivals = df['High_Arrivals']\n",
    "\n",
    "# Model 2: Predict if Departures will be high\n",
    "# Features: 'Country', 'No of holidays', 'Year', 'Month', 'Arrivals'\n",
    "X_departures = df[['No of holidays', 'Year', 'Month', 'Arrivals']]\n",
    "X_departures = pd.concat([X_departures, pd.get_dummies(df['Country'], prefix='Country', drop_first=True)], axis=1)\n",
    "y_departures = df['High_Departures']\n",
    "\n",
    "# Split data for Arrivals model\n",
    "X_train_arr, X_test_arr, y_train_arr, y_test_arr = train_test_split(\n",
    "    X_arrivals, y_arrivals, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Split data for Departures model\n",
    "X_train_dep, X_test_dep, y_train_dep, y_test_dep = train_test_split(\n",
    "    X_departures, y_departures, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train Arrivals classification model\n",
    "log_reg_arrivals = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg_arrivals.fit(X_train_arr, y_train_arr)\n",
    "\n",
    "# Train Departures classification model\n",
    "log_reg_departures = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg_departures.fit(X_train_dep, y_train_dep)\n",
    "\n",
    "# Evaluate classification model\n",
    "def evaluate_classification_model(model, X_test, y_test, model_name=\"Classification Model\"):\n",
    "    \"\"\"\n",
    "    Evaluates a classification model using standard metrics and prints the results.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : estimator object\n",
    "        The trained classification model\n",
    "    X_test : array-like\n",
    "        Test features\n",
    "    y_test : array-like\n",
    "        True target values\n",
    "    model_name : str\n",
    "        Name of the model for printing\n",
    "    \"\"\"\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probability of positive class\n",
    "    \n",
    "    # Print header\n",
    "    print(f\"\\n===== {model_name} EVALUATION =====\\n\")\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    print(\"Confusion Matrix:\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    try:\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    except:\n",
    "        auc = \"N/A\"\n",
    "    \n",
    "    # Print summary metrics\n",
    "    print(\"\\nSummary Metrics:\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"AUC-ROC:   {auc}\")\n",
    "    \n",
    "    # Return predictions and metrics for further analysis\n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': auc\n",
    "    }\n",
    "    \n",
    "    return y_pred, y_pred_proba, metrics\n",
    "\n",
    "# Visualize classification results\n",
    "def plot_classification_results(y_test, y_pred, y_pred_proba, title=\"Classification Results\"):\n",
    "    \"\"\"\n",
    "    Creates visualization plots for classification model evaluation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_test : array-like\n",
    "        True target values\n",
    "    y_pred : array-like\n",
    "        Predicted class values\n",
    "    y_pred_proba : array-like\n",
    "        Predicted probabilities for the positive class\n",
    "    title : str\n",
    "        Plot title\n",
    "    \"\"\"\n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "    axes[0].set_title(f'Confusion Matrix ({title})')\n",
    "    axes[0].set_xlabel('Predicted Label')\n",
    "    axes[0].set_ylabel('True Label')\n",
    "    \n",
    "    # Try to plot ROC curve\n",
    "    try:\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        \n",
    "        axes[1].plot(fpr, tpr, label=f'AUC = {auc:.4f}')\n",
    "        axes[1].plot([0, 1], [0, 1], 'k--')\n",
    "        axes[1].set_xlabel('False Positive Rate')\n",
    "        axes[1].set_ylabel('True Positive Rate')\n",
    "        axes[1].set_title(f'ROC Curve ({title})')\n",
    "        axes[1].legend(loc='lower right')\n",
    "    except:\n",
    "        axes[1].text(0.5, 0.5, 'ROC curve unavailable', \n",
    "                     horizontalalignment='center', verticalalignment='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate both models\n",
    "y_pred_arr, y_pred_proba_arr, metrics_arr = evaluate_classification_model(\n",
    "    log_reg_arrivals, X_test_arr, y_test_arr, \"Arrivals Classification Model\"\n",
    ")\n",
    "\n",
    "y_pred_dep, y_pred_proba_dep, metrics_dep = evaluate_classification_model(\n",
    "    log_reg_departures, X_test_dep, y_test_dep, \"Departures Classification Model\"\n",
    ")\n",
    "\n",
    "# Plot results for both models\n",
    "plot_classification_results(y_test_arr, y_pred_arr, y_pred_proba_arr, \"Arrivals Classification\")\n",
    "plot_classification_results(y_test_dep, y_pred_dep, y_pred_proba_dep, \"Departures Classification\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
