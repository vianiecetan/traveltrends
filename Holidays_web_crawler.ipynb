{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Section 1 : Web crawling from www.timeanddate.com**\n",
        "\n",
        "This section of the script scrapes holiday data from the \"timeanddate.com\" website for different countries and years, and saves the results in an Excel file.\n",
        "\n",
        "\n",
        "1.   **Imports Libraries**: It uses requests for making HTTP requests, BeautifulSoup for parsing HTML, pandas for organizing data, and tqdm for showing a progress bar.\n",
        "2.   **Sets Up URLs**: It defines base URLs to fetch the country list and holiday data for each country and year.\n",
        "3.   **Gets Country List**: The script sends a request to the website, extracts a list of countries, and stores them in a dictionary with country codes and names.\n",
        "4.    **Prepares for Data Collection**: It sets up a dictionary to hold holiday data for each country and year.\n",
        "5.   **Scrapes Data**: For each country and year, it sends a request, extracts the holiday data from the webpage, and adds it to the dictionary.\n",
        "6.   **Stores and Saves Data**: The collected data is stored in a pandas DataFrame and saved to an Excel file called holidays.xlsx.\n",
        "7.   **Completion**: It prints a message when the data is successfully saved."
      ],
      "metadata": {
        "id": "kMdsD4hzP268"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests beautifulsoup4 pandas openpyxl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2p6PsSsQBAAe",
        "outputId": "7229d42b-ef18-4e45-dcf6-35c277879c58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlXWUv_Z7RpS",
        "outputId": "82405d04-5fad-41e0-e457-fefe3ccfb62a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping holidays: 100%|██████████| 235/235 [07:47<00:00,  1.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully saved to holidays.xlsx\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "# Base URL template\n",
        "BASE_URL = \"https://www.timeanddate.com/calendar/custom.html?year={year}&country={country}&cols=3&df=1&hol=1&lang=en\"\n",
        "\n",
        "# Main URL to get country list\n",
        "URL = \"https://www.timeanddate.com/calendar/custom.html\"\n",
        "\n",
        "# Get the list of countries from the dropdown on the website\n",
        "resp = requests.get(URL)\n",
        "soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "country_select = soup.find(\"select\", {\"id\": \"sf_country\"})\n",
        "\n",
        "# Extract country codes and names\n",
        "countries = {option[\"value\"]: option.text for option in country_select.find_all(\"option\")}\n",
        "\n",
        "# Set the years to extract (2020-2028)\n",
        "years = list(range(2020, 2029))\n",
        "\n",
        "# List to store extracted holiday data\n",
        "holiday_data = []\n",
        "\n",
        "def format_date(dd_mmm, year):\n",
        "    try:\n",
        "        # Convert \"1 Jan\" to a datetime object\n",
        "        date_obj = datetime.strptime(f\"{dd_mmm} {year}\", \"%d %b %Y\")\n",
        "\n",
        "        # Convert to required formats\n",
        "        full_date = date_obj.strftime(\"%Y-%m-%d\")  # YYYY-MM-DD\n",
        "        day_month = date_obj.strftime(\"%d-%m\")  # DD-MM\n",
        "\n",
        "        return full_date, day_month\n",
        "    except ValueError:\n",
        "        return None, None  # Handle unexpected formats\n",
        "\n",
        "# Iterate over each country and year\n",
        "for country_code, country_name in tqdm(countries.items(), desc=\"Scraping holidays\"):\n",
        "    for year in years:\n",
        "        url = BASE_URL.format(year=year, country=country_code)\n",
        "        resp = requests.get(url)\n",
        "\n",
        "        if resp.status_code == 200:\n",
        "            soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "            holiday_table = soup.find(\"table\", {\"class\": \"cl1h\"})\n",
        "\n",
        "            if holiday_table:\n",
        "                for holiday_row in holiday_table.find_all(\"tr\"):\n",
        "                    date_span = holiday_row.find(\"span\", {\"class\": \"co1\"})\n",
        "                    name_td = holiday_row.find(\"a\")\n",
        "\n",
        "                    if date_span and name_td:\n",
        "                        raw_date = date_span.text.strip()\n",
        "                        full_date, day_month = format_date(raw_date, year)  # Format date\n",
        "                        holiday_name = name_td.text\n",
        "\n",
        "                        if full_date:\n",
        "                            # Append row to list\n",
        "                            holiday_data.append([full_date, holiday_name, country_name, year, day_month])\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(holiday_data, columns=[\"Date\", \"Event\", \"Country\", \"Year\", \"Day-Month\"])\n",
        "\n",
        "# Save to Excel\n",
        "df.to_excel(\"holidays.xlsx\", index=False)\n",
        "\n",
        "print(\"Data successfully saved to holidays.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section 2 : Removing duplicates**\n",
        "\n",
        "This section looks through the list of holidays in a year and remove any duplicate dates."
      ],
      "metadata": {
        "id": "YFbwqXkURVlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the excel file from Section 1\n",
        "file_path = \"holidays.xlsx\"\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Remove duplicate rows\n",
        "df_cleaned = df.drop_duplicates()\n",
        "\n",
        "# Save the cleaned data back to an Excel file\n",
        "cleaned_file_path = \"holidays_cleaned.xlsx\"\n",
        "df_cleaned.to_excel(cleaned_file_path, index=False)\n",
        "\n",
        "print(\"Duplicates removed. Cleaned data saved to:\", cleaned_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tesQ7nhIrYm",
        "outputId": "31c7d303-fd9a-4cd8-d3f9-005b6f1ec8c9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duplicates removed. Cleaned data saved to: holidays_cleaned.xlsx\n"
          ]
        }
      ]
    }
  ]
}